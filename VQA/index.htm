<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
   
    <title>Perceptual Visual Quality Assessment</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="./css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
</head>

        <!-- you should probably put some google analytics / meta bits and pieces
	    here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', '??????????');
  </script>
    -->

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1><b><center>Perceptual Visual Quality Assessment</center></b></h1>
                                <div class="container-sm">
                                    <div class="row justify-content-md-center">
									                                        <div class="col-sm-auto">
                                            <p><a href='https://seis.bristol.ac.uk/~eexfz/index.htm'>Fan Zhang</a></p>
                                        </div>
									<div class="col-sm-auto">
                                            <p><a href='http://www.bristol.ac.uk/engineering/people/paul-r-hill/index.html'>David Bull</a></p>
                                        </div>
									
                                    </div>
									<center><p>University of Bristol</p></center>
                                </div>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.png" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VILogo.jpg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <h2>About</h2>
                <p>It is known that the human visual system (HVS) employs independent processes (distortion detection and artifact perception also often referred to as near-threshold and suprathreshold distortion perception) to assess video quality for various distortion levels. Visual masking effects also play an important role in video distortion perception, especially within spatial and temporal textures. In this work, a novel perceptionbased hybrid model for video quality assessment is developed. This simulates the HVS perception process by adaptively combining noticeable distortion and blurring artifacts using an enhanced nonlinear model. Noticeable distortion is defined by thresholding absolute differences using spatial and temporal tolerance maps that characterize texture masking effects, and this makes a significant contribution to quality assessment when the quality of the distorted video is similar to that of the original video. Characterization of blurring artifacts, estimated by computing high frequency energy variations and weighted with motion speed, is found to further improve metric performance. This is especially true for low quality cases. All stages of our model exploit the orientation selectivity and shift invariance properties of the dual-tree complex wavelet transform. This not only helps to improve the performance but also offers the potential for new low complexity in-loop application. </p>
            </div>
            <hr />
            <div class="container-md">
                <h2 id="poster">Performance</h2>
                Our approach is evaluated on both the Video Quality Experts Group (VQEG) full reference television Phase I and the Laboratory for Image and Video Engineering (LIVE) video databases. The resulting overall performance is superior to the existing metrics, exhibiting statistically better or equivalent performance with significantly lower complexity.


            </div>
            <hr />
            <div class="container-md">
                <h2 id="downloads">Useful links</h2>
<p>[<strong><a href="PVM_code.zip">DOWNLOAD</a></strong>] PVM Matlab Code</p>
            </div>
			<hr />
            <div class="container-md">
                <h2>Reference</h2>
<p>@article{zhang2015perception,<br>
  title={A perception-based hybrid model for video quality assessment},<br>
  author={Zhang, Fan and Bull, David R},<br>
  journal={IEEE Transactions on Circuits and Systems for Video Technology},<br>
  volume={26},<br>
  number={6},<br>
  pages={1017--1028},<br>
  year={2015},<br>
  publisher={IEEE}<br>
}</p>

            </div>
			<hr />
            

        </div>
    </div>
</body>

</html>
