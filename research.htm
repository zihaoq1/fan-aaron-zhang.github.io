<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Dr Fan (Aaron) Zhang - Research</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="./css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
</head>

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
                        <div class="col-md-3">
                            <div class="title">
							<br>
							<br>
                                <p><img src="Fan.jpg" width="100%" height="20%" class="center" /></p>
                            </div>
                        </div>
                        <div class="col-md-5">
                            <div class="title">
							<br>
							<br>
                                <h1>Dr Fan Zhang (Aaron)</h1>
								
								<b><font SIZE="4">Research Fellow</font></b><br>
								in Image and Video Communication<br>
								<br>
								1.23, 1 Cathedral Square<br>
                                University of Bristol<br>
                                Bristol BS1 5DD, United Kingdom<br>
                                fan.zhang@bristol.ac.uk<br>
								
								<ul class="list-inline list-social-icons mb-0">
								<br>
                                    <li class="list-inline-item">
                                        <a href="https://scholar.google.com/citations?hl=en&user=BBujJNcAAAAJ">
                                            <span class="fa-stack fa-lg">
                                                <i class="ai ai-google-scholar-square ai-2x"></i>
                                            </span>
                                        </a>
                                    </li>
<!--                                     <li class="list-inline-item">
                                        <a href="https://www.linkedin.com/in/fan-zhang-b32ba430/">
                                            <span class="fa-stack fa-lg">
												<i class="fa fa-square fa-stack-2x"></i>
                                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                            </span>
                                        </a>
                                    </li> -->
                                    <li class="list-inline-item">
                                        <a href="CV_2021.pdf">
                                            <span class="fa-stack fa-lg">
                                                <i class="ai ai-cv-square ai-2x"></i>
                                            </span>
                                        </a>
                                    </li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-md-4">
						<br>
						<br>
						<br>
						    <p><a href='https://www.bristol.ac.uk'><img src="uob-logo.svg" width="70%" height="20%" alt=""></a></p>
                            <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="bvilogo.png" width="65%" height="20%" alt=""></a></p>										
                            <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="VILogo.jpg" width="80%" height="20%" alt=""></a></p>


                        </div>
                    </div>
                </div>
            </div>
			<br>
            <hr />
            <div class="container-md">
                <h2 id="projects">Research Projects</h2>

			<br>
            <div class="researchlist">
			<font size=+1>
			<b><font SIZE="4">Deep Video Coding</font></b>
			</font>
			<br>
			<ul>
			<li><a href="CNN-PP/">Video Compression with CNN-based Post Processing</a>
                    <p>This is a new CNN-based post-processing approach, which has been integrated with two state-of-the-art coding standards, VVC and AV1. It offers consistent coding gains on all tested sequences at various spatial resolutions, with average bit rate savings of 4.0% and 5.8% against original VVC and AV1 respectively (based on the assessment of PSNR). This network has also been trained with perceptually inspired loss functions, swhich have further improved reconstruction quality based on perceptual quality assessment (VMAF), with average coding gains of 13.9% over VVC and 10.5% against AV1.</p></li>
					                <li><a href="ViSTRA/">ViSTRA: Video Compression based on Resolution Adaptation</a>
                    <p>ViSTRA a new video compression framework which exploits adaptation of spatial/temporal resolution and effective bit depth, down-sampling these parameters at the encoder based on perceptual criteria, and up-sampling at the decoder using a deep convolution neural network.</p></li>
						<font size=+1>
			</ul>
			<b><font SIZE="4">Video Quality Assessment</font></b>
			</font>
			<br>
			<ul>
			<li>    <a href="BVI-HFR/">BVI-HFR: A High Frame Rate Video Database</a>
                    <p>The BVI-HFR video database is a publicly available high frame rate video database, and contains 22 unique HD video sequences at frame rates up to 120 Hz. Subjective evaluations of 51 participants on the sequences in the BVI-HFR video database have shown a clear relationship between frame rate and perceived quality (MOS), although we do see the effect of diminishing returns.</p></li>
							
							<li><a href="BVI-HD/">BVI-HD: A Perceptual Video Quality Database for HEVC and Texture Synthesis Compressed Content</a>
                    <p>This is a new high definition video quality database, which contains 32 reference and 384 distorted video sequences plus subjective scores. They are also associated with subjective opinion scores collected from a total of 86 subjects, using a double stimulus test methodology. </p></li>
						<font size=+1>
											
											<li><a href="Duration/">Optimal Presentation Duration for Video Quality Assessment</a>
                    <p>In this work, we explore the impact of reducing sequence length upon perceptual accuracy when identifying compression artifacts. We argue that sequences between 5 and 10s produce satisfactory levels of accuracy but the practical benefits of acquiring more data lead us to recommend the use of 5s sequences for future VQA studies that use the single and double stimulus continuous quality scale methodologies.</p></li>
										
										<li><a href="VQA/">PVM: Perceptual Visual Quality Assessment</a>
                    <p>PVM is a novel perceptionbased hybrid model for video quality assessment, which simulates the HVS perception process by adaptively combining noticeable distortion and blurring artifacts using an enhanced nonlinear model. All stages of our model exploit the orientation selectivity and shift invariance properties of the dual-tree complex wavelet transform. This not only helps to improve the performance but also offers the potential for new low complexity in-loop application. </p></li>
					</ul>
			<b><font SIZE="4">Creative Technology</font></b>
			</font>
			<br>
			<ul>
			<li> <a href="Drone/">A Simulation Environment for Drone Cinematography</a>
                    <p>A workflow has been developed for the simulation of drone operations exploiting realistic background environments constructed within Unreal Engine 4 (UE4). This simulation tool will contribute to enhanced productivity, improved safety (awareness and mitigations for crowds and buildings), improved confidence of operators and directors and ultimately enhanced quality of viewer experience.</p></li>
			
						<li><a href="MultiDrone/">Drone Cinematography</a>
                    <p>In this project, we have refined the grammar of typical shot types based on our interviews and on experience gained during planning and shooting of live footage. A series of subjective experiments were also conducted based on simulation videos in order to evaluate optimum drone parameters in typical single drone shot types.</p></li>
						<font size=+1>
						</ul>
			<b><font SIZE="4">Perceptual Video Coding</font></b>
			</font>
			<br>
			<ul>
			<li>	<a href="RDO/">Rate Quality Optimisation: Lagrangian Optimisation</a>
                    <p>In this work, we conducted a comprehensive analysis of the results of a Lagrange multiplier selection experiment conducted on various video content using H.264/AVC and HEVC reference encoders. These results show that the original Lagrange multiplier selection methods, employed in both video encoders, are able to achieve optimum rate-distortion performance for I and P frames, but fail to perform well for B frames. The relationship is identified between the optimum Lagrange multipliers for B frames and distortion information obtained from the experimental results, leading to a novel Lagrange multiplier determination approach. </p></li>
					</ul>









					
			
					
            </div>



                <h3></h3>
            </div>
		</div>
    </div>        
</body>

</html>
