<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Dr Fan (Aaron) Zhang</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="./css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
</head>

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
                        <div class="col-md-3">

						<br>
						<br>
						    <p><a href='https://www.bristol.ac.uk'><img src="uob-logo.svg" width="90%" height="20%" alt=""></a></p>
                            <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="bvilogo.png" width="85%" height="20%" alt=""></a></p>
                            <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="VILogo.jpg" width="95%" height="30%" alt=""></a></p>


                        </div>
                        <div class="col-md-6">
                            <div class="title">
							<br>
							<br>
                                <h1>Dr Fan (Aaron) Zhang </h1>

								<b><font size="+1">Senior Lecturer</font></b><br>
								in Visual Communications<br>
								<br>
								School of Computer Science<br>
								University of Bristol<br>
		
                                <a href='mailto:fan.zhang@bristol.ac.uk'>fan.zhang@bristol.ac.uk</a><br>

								<ul class="list-inline list-social-icons mb-0">
								<br>
                                    <li class="list-inline-item">
                                        <a href="https://scholar.google.com/citations?hl=en&user=BBujJNcAAAAJ">
                                            <span class="fa-3x">
                                                <i class="ai ai-google-scholar-square"></i>
                                            </span>
                                        </a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="https://www.linkedin.com/in/fan-zhang-b32ba430/">
                                            <span class="fa-3x">
												<i class="fab fa-linkedin"></i>
                                            </span>
                                        </a>
                                    </li>
									<li class="list-inline-item">
                                        <a href="https://www.github.com/fan-aaron-zhang">
                                            <span class="fa-3x">
                                                <i class="fab fa-github-square"></i>
                                            </span>
                                        </a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="https://research-information.bris.ac.uk/en/persons/fan-zhang">
                                            <span class="fa-3x">
                                                <i class="ai ai-cv-square"></i>
                                            </span>
                                        </a>
                                    </li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-md-3">
						<div class="title">
							<br>
							<br>
                                <p><img src="Fan.jpg" width="100%" height="20%" class="center" /></p>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
			<br>
            <div class="container-md">
                <h2>About</h2> I am a Senior Lecturer in Visual Communications within the <A HREF="https://www.bristol.ac.uk/engineering/schools/computer-science/">School of Computer Science</a>, <A HREF="http://www.bris.ac.uk/">University of Bristol</A>. I am also a member of the <A HREF="http://www.bristol.ac.uk/vi-lab/">Visual Information Laboratory</A> and the <A HREF="https://www.bristol.ac.uk/vision-institute/"> Bristol Vision Institute</a>, which are led by <A HREF="https://david-bull.github.io/">Prof. David Bull</a>. I have been involved in many research projects on video compression, quality assessment, image processing and creative technology. I have published over 80 academic papers, and have contributed to two books on video compression. My work on super-resolusion-based video compression, and deep video coding training database has contributed to international standardization processes. I was a co-winner of the 2017 IEEE ICIP Grand Challenge on Video Compression and the 2023 IEEE/CVF WACV Grand Challenge on HDR Video Quality Measurement. I am currently an associate editor of <A HREF="https://ieee-cas.org/publications/transactions-circuits-and-systems-video-technology">IEEE TCSVT </A>(2021-present), and has been serving as a reviewer for a number of top tier conferences and journals including CVPR, WACV, TIP, TMM, SPL and TCSVT. I am also a member of the Visual Signal Processing and Communications Technical Committee associated with the IEEE Circuits and Systems Society.
            </div>
			<hr />
            <div class="container-md">
                <h2 id="projects">Important Download Links</h2>
                <ul>
					<li><b><a href="BVIdatabases/">[Download]</a></b> databases. </li>
					<li><b><a href="BVIsourcecode/">[Download]</a></b> source code.  </li>
                </ul>
            </div>
            <hr />
                  <div class="container-md">
                      <h2 id="projects">Teaching</h2>
                      <ul>
                <li><b><a href="https://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?unitCode=EENGM4021">EENGM4021</a></b> Image and Video Coding (Unit Director: Prof David Bull) </li>
                <li><b><a href="https://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?unitCode=EENGM0004">EENGM0004</a></b> Engineering Research Skills (Unit Director)</li>
                <li><b><a href="https://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?unitCode=COMSM0129">COMSM0129</a></b> Augmenting the Real World (Unit Director)</li>
                      </ul>
                  </div>
			<hr />
            <div class="container-md">
                <h2 id="projects">News & Activities</h2>
                <ul>
					<li><b>Apr 2024:</b> The paper on "<A HREF="https://arxiv.org/abs/2011.09190">CVEGAN: a perceptually-inspired GAN for compressed video enhancement</a> has been accepted by <a HREF="https://www.sciencedirect.com/journal/signal-processing-image-communication">Signal Processing: Image Communication</a>.
					<li><b>Mar 2024:</b> I became a member of the <A HREF="https://ieee-cas.org/technical-committee/visual-signal-processing-and-communications-vspc">Visual Signal Processing and Communications Technical Committee</A> associated with the <A HREF="https://ieee-cas.org/">IEEE CAS Society</A>.</li>
					<li><b>Feb 2024:</b> <font style="color:red">SIX</font> papers have been accepted by <a HREF="https://2024.picturecodingsymposium.org/">Picture Coding Symposium (PCS) 2024</a>, including <A HREF="https://arxiv.org/abs/2312.08859">BVI-Artefact database</A>, <A HREF="https://arxiv.org/abs/2312.02605">lightweight leant video codec</A>, <A HREF="https://arxiv.org/abs/2312.08864">RankDVQA-mini</A>, <A HREF="https://arxiv.org/abs/2312.12317">VQA for UGC transcoding</A>, <A HREF="https://arxiv.org/abs/2401.00523">low complexity super resolution</A> and <A HREF="https://arxiv.org/abs/2402.01596">INR-based immersive video coding</A>.					
					<li><b>Dec 2023:</b> The paper on "<A HREF="https://arxiv.org/abs/2303.09508">LDMVFI: Video Frame Interpolation with Latent Diffusion Models</a> has been accepted by <a HREF="https://aaai.org/aaai-conference/">AAAI 2024</a>.
					<li><b>Oct 2023:</b> Our paper on "<A HREF="https://arxiv.org/abs/2202.08595">RankDVQA: Deep VQA based on Ranking-inspired Hybrid Training</a>" has been accepted by <a HREF="https://wacv2024.thecvf.com/">IEEE/CVF WACV 2024<a>.
					<li><b>Oct 2023:</b> The paper on "<A HREF="https://arxiv.org/abs/2210.00823">BVI-VFI: A Video Quality Database for Video Frame Interpolation</a>" has been accepted by IEEE Trans. on Image Processing.
					<li><b>Sept 2023:</b> Our paper on "<A HREF="https://arxiv.org/abs/2306.09818">HiNeRV: Video Compression with Hierarchical Encoding based Neural Representation</a>" has been accepted by <a HREF="https://nips.cc/">NeurIPS 2023<a>.
					<li><b>June 2023:</b> Our paper on "<A HREF="https://arxiv.org/abs/2302.08455">ST-MFNet Mini: Knowledge Distillation-Driven Frame Interpolation</a>" has been accepted by <a HREF="https://2023.ieeeicip.org/">IEEE ICIP 2023<a>.
					<li><b>Apr 2023:</b> We have received an <a HREF="amzn.to/ara-fall-2022">Amazon Research Award</a> to conduct research on video quality assessment.
					<li><b>Jan 2023:</b> We participated the <a HREF="https://sites.google.com/view/wacv2023-workshop-quality-va/competition?authuser=0">Grand Challenge on HDR Video Quality Measurement</a> in IEEE/CVF WACV 2023, organised by Amazon Prime Video. Our submission ranked <font style="color:red">the FIRST</font> in the no reference VQA track.
						</ul>
				<p><a id="showOlderNews" href="#olderNews">[Older news and activities]</a></p>
				<div id="olderNews">
				<a name="olderNews" />
					<ul>
					<li><b>Dec 2022:</b> Our paper on <a HREF="https://arxiv.org/abs/2207.08119">FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation</a> was shortlised as one of five best papers in PCS 2022.
					<li><b>Oct 2022:</b> We have released a video quality database, <a HREF="https://danielism97.github.io/BVI-VFI-database/">BVI-VFI</a>, for video frame interpolation.
					<li><b>June 2022:</b> Our team participated the <a HREF="http://compression.cc/">Challenge on Learned Image Compression (CLIC)</a> in IEEE/CVF CVPR 2022, and ranks <font style="color:red">top six</font> in the video track.
					<li><b>June 2022:</b> Three papers that I contributed to have been accepted by IEEE ICIP 2022, including <A HREF="https://danielism97.github.io/EDC/">deformable convolution based VFI</A>, <A HREF="https://danielism97.github.io/BVI-VFI/">BVI-VFI database</A> and <A HREF="https://arxiv.org/abs/2202.12852">AI-based volumetric video compression</A>.
					<li><b>June 2022:</b> Our paper on "<A HREF="https://arxiv.org/abs/2111.15483">ST-MFNet: Spatio-Temporal Multi-Flow Network for Video Frame Interpolation</a>" has been published in the proceedings of <a HREF="https://cvpr2021.thecvf.com/">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022<a>.
					<li><b>May 2022:</b> Our team participated the <a HREF="https://mailchi.mp/ieee-cas.org/ieee-cass-seasonal-school-on-technology-and-agribusiness-391034?e=2bef362975">Grand Challenge on Neural Network-based Video Coding</a> in IEEE ISCAS 2022, and ranks the <font style="color:red">Second Place</font> in the hybrid track.
					<li><b>May 2022:</b> Source code has been released for our deep video compression algorithms: <A HREF="ViSTRA/">ViSTRA</A>, <A HREF="CNN-PP/">CNN-based post-processing</A>, <A HREF="MFRNet/">MFRNet</A> and <A HREF="CVE-GAN/">CVEGAN</A>.
					<li><b>Sept 2021:</b> I joined the editorial board of <A HREF="https://www.frontiersin.org/journals/signal-processing">Frontiers in in Signal Processing </A>as a guest associate editor for the research topic of "<A HREF="https://www.frontiersin.org/research-topics/26462/video-content-production-and-delivery-over-ip-networks-and-distributed-computing-facilities">Video Content Production and Delivery Over IP Networks and Distributed Computing Facilities</A>".</li>
					<li><b>Aug 2021:</b> Our paper on <A HREF="https://arxiv.org/abs/2003.13552">"BVI-DVC: A Training Database for Deep Video Compression"</A> has been accepted by the IEEE Transactions on Multimedia.</li>
					<li><b>July 2021:</b> VI-Lab has successfully hosted the Picture Coding Symposium 2021 (<a href="https://pcs2021.org/">PCS 2021</a>).</li>
					<li><b>July 2021:</b> I gave a <A HREF="https://youtu.be/cYZVuL-3hOQ">presentation</A> on "<A HREF="https://arxiv.org/abs/2103.06338">Enhancing VMAF through New Feature Integration and Model Combination</A>" in the Special Session on "<A HREF="https://pcs2021.org/accepted-special-sessions/">Perceptually Driven Techniques for Video Compression and Quality Assessment</A>" of PCS 2021.</li>
					<li><b>June 2021:</b> Our paper on "<A HREF="https://doi.org/10.1016/j.image.2021.116355">ViSTRA2: Video Coding using Spatial Resolution and Effective Bit Depth Adaptation.</A>" was publish in the Elsevier Signal Processing: Image Communication.</li>
					<li><b>May 2021:</b> I became a lecturer within the <A HREF="http://www.bristol.ac.uk/engineering/departments/eeng/">Department of Electrical and Electronic Engineering</a>, <A HREF="http://www.bris.ac.uk/">University of Bristol</A>.</li>
					<li><b>Jan 2021:</b> <a href="https://pcs2021.org/">PCS 2021</a> Keynotes, Workshops and Panel Sessions announced. </li>
					<li><b>Jan 2021:</b> Our paper on <A HREF="https://arxiv.org/abs/2009.07583">"Video Compression with CNN-based Post Processing"</A> has been accepted by the IEEE MultiMedia Magazine.</li>
                	<li><b>Dec 2020:</b> I joined the editorial board of <A HREF="https://ieee-cas.org/publications/transactions-circuits-and-systems-video-technology">IEEE T-CSVT </A>as an associate editor (2021-2022).</li>
					<li><b>Nov 2020:</b> Our paper on <A HREF="https://arxiv.org/abs/2007.07099">"MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering"</A> has been accepted by the IEEE Journal of Selected Topics in Singal Processing <A HREF="https://signalprocessingsociety.org/blog/ieee-jstsp-special-issue-deep-learning-imagevideo-restoration-and-compression">Special Issue</A> on Deep Learning for Image/Video Restoration and Compression.</li>
					<li><b>July 2020:</b> We organised a Grand Challenge <A HREF="https://vilab.blogs.bristol.ac.uk/2019/11/icme2020-grand-challenge-encoding-in-the-dark/">"Encoding in the Dark"</A> in the IEEE ICME 2020. </li>
					<li><b>Apr 2020:</b> We released a large video database, <a href="BVI-DVC/index.htm">BVI-DVC</a>, for training deep learning based video coding algorithms. It has been identified by <a href="https://jvet-experts.org/doc_end_user/current_document.php?id=10484">MPEG JVET AHG11</a> (neural network-based video coding) as one of their training datasets.</li>
					<li><b>Jan 2020:</b> VI-Lab won DASA award for research into <a href="DASA/">Learning-Optimal Deep Video Compression</a>, collaborating with Thales UK.</li>
					<li><b>Nov 2019:</b> VI-Lab announced as host of the 2021 Picture Coding Symposium (<a href="https://pcs2021.org/">PCS2021</a>), where I served as Finance Chair.</li>

				</div>
				</ul>
            </div>

            <hr />
			            <div class="container-md">
                <h2>Primary Research Areas</h2>

				 <div class="row">
                    <div class="row vertical-align">
				 <div class="col-md-6">
				<ul>
                    <li><b>Deep Video Coding</b></li>
					<ul>
						<li><a href="https://hmkx.github.io/hinerv/">HiNeRV: video compression with hierarchical encoding-based neural representation</a></li>
						<li><a href="CVE-GAN/">CVEGAN: A Perceptually-inspired GAN for Video Compression</a></li>
						<li><a href="DASA/">Learning-optimal Deep Visual Compression</a></li>
						<li><a href="CNN-PP/">Video Compression with CNN-based Post Processing</a></li>
						<li><a href="MFRNet/">MFRNet: A New CNN Architecture for Video Compression</a></li>
						<li><a href="ViSTRA/">ViSTRA: Video Compression based on Resolution Adaptation</a></li>
						<li><a href="BVI-DVC/">BVI-DVC: A Training Database for Deep Video Compression</a></li>
						<li><a href="LowComplexity/">Reduced complexity architectures</a></li>


                    </ul>
                </ul>
				</div>
				 <div class="col-md-6">
				<ul>
                    <li><b>Video Quality Assessment</b></li>
					<ul>
						<li><a href="VQA/">RankDVQA: Deep VQA based on a Novel Hybrid Training Methodology</a></li>
						<li><a href="BVIdatabases/">BVI Databases for Video Compression and Quality Assessment</a></li>
						<li><a href="FRQM/">FRQM: A Frame Rate Dependent Video Quality Metric</a></li>
						<li><a href="BVI-HFR/">BVI-HFR: A High Frame Rate Video Database</a></li>
						<li><a href="WhatsonTV/">What's on TV?</a></li>
						<li><a href="Duration/">Optimal Presentation Duration for Video Quality Assessment</a></li>
						<li><a href="VQA/">PVM: Perceptual Visual Quality Assessment</a></li>

                    </ul>
                </ul>
				</div>

				<div class="col-md-6">
				<ul>
                    <li><b>Perceptual Video Coding</b></li>
					<ul>
						<li><a href="RDO/">Rate Quality Optimisation: Lagrangian Optimisation</a></li>
						<li><a href="PVC/">Parametric Video Coding</a></li>
						<li><a href="BIV-CC/">Codec Comparisons</a></li>
						<br>
                    </ul>
				</ul>
				</div>
				<div class="col-md-6">
				<ul>
                    <li><b>Creative Technology</b></li>
					<ul>
						<li><a href="Drone/">A Simulation Environment for Drone Cinematography</a></li>
						<li><a href="MultiDrone/">Drone Cinematography</a></li>
						<li><a href="https://danielism97.github.io/ST-MFNet">Video Frame Interpolation</a></li>
						<li><a href="https://github.com/danier97/LDMVFI">LDMVFI: Video Frame Interpolation with Latent Diffusion Models</a></li>
						<li>Immersive (HDR/HFR/HSR/360/volumetric) video</li>

                    </ul>
                </ul>
				</div>


				</div>
            </div>
    <hr />
			
			            <div class="container-md">
                <h2>Signature Research Projects</h2>
			<br>
			
			<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
	    <td class="thumbs"><p>
		 </p><div class="col-sm-3 abbr"><abbr class="badge">arXiv 2024</abbr></div>
        <img src="./MTKD.svg" width="100%" \="">
    </p></td>
	
    
    <td class="detail">   
    <b id="papertitle"> MTKD: Multi-Teacher Knowledge Distillation for Image Super-Resolution </b>
    <br>
    Yuxuan Jiang, Chen Feng, Fan Zhang, David Bull
    <br>
    <em>arXiv</em>, 2024
    <br>
    <a href="https://arxiv.org/abs/2404.09571" target="_blank" style="font-style:normal;">[arXiv]</a>   
    </td>
    </tr>
    </tbody></table>
</div>
<br>				
			
			<br>
			
			<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
	    <td class="thumbs"><p>
		 </p><div class="col-sm-3 abbr"><abbr class="badge">AAAI 2024</abbr></div>
        <img src="./LDMVFI.svg" width="100%" \="">
    </p></td>
	
    
    <td class="detail">   
    <b id="papertitle"> LDMVFI: Video Frame Interpolation with Latent Diffusion Models </b>
    <br>
     Duolikun Danier, Fan Zhang, David Bull
    <br>
    <em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2024
    <br>
    <a href="https://arxiv.org/abs/2303.09508" target="_blank" style="font-style:normal;">[arXiv]</a>   
    <a href="https://github.com/danier97/LDMVFI" target="_blank" style="font-style:normal;">[code]</a>   
    </td>
    </tr>
    </tbody></table>
</div>
<br>


<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td class="thumbs"><p>
        </p><div class="col-sm-3 abbr"><abbr class="badge">WACV 2024</abbr></div>
        <img src="https://danier97.github.io/thumbnails/rankdvqa.PNG" width="100%" \="">
    <p></p></td>
    <td class="detail">   
    <b id="papertitle"> RankDVQA: Deep VQA based on Ranking-inspired Hybrid Training </b>
    <br>
    Chen Feng, Duolikun Danier, Fan Zhang, David Bull
    <br>
    <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<b>WACV</b>), 2024
    <br>
    <a href="https://arxiv.org/abs/2202.08595" target="_blank" style="font-style:normal;">[arXiv]</a> 
    <a href="https://chenfeng-bristol.github.io/RankDVQA/" target="_blank" style="font-style:normal;">[project]</a>  
	<a href="https://github.com/ChenFeng-Bristol/RankDVQA_release" target="_blank" style="font-style:normal;">[code]</a> 	
    </td>
    </tr>
    </tbody></table>
    <!-- <a href="https://github.com/crispianm/ST-MFNet-Mini" target="_blank"><p class="lab la-github"></p>&#32;</a>
    <a href="https://github.com/crispianm/ST-MFNet-Mini" target="_blank" style="font-style:normal;">github</a>&#8201;&#8201;&#8201; -->
<!-- </div> -->
</div>
<br>

<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
	    <td class="thumbs"><p>
		 </p><div class="col-sm-3 abbr"><abbr class="badge">NeurIPS 2023</abbr></div>
        <img src="https://hmkx.github.io/hinerv/figs/hinerv.png" width="100%" \="">
    </p></td>
	
    
    <td class="detail">   
    <b id="papertitle"> HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation </b>
    <br>
     Ho Man Kwan, Ge Gao, Fan Zhang, Andrew Gower, David Bull
    <br>
    <em>Conference on Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023
    <br>
    <a href="https://arxiv.org/abs/2306.09818" target="_blank" style="font-style:normal;">[arXiv]</a>  
    <a href="https://hmkx.github.io/hinerv/" target="_blank" style="font-style:normal;">[project]</a>	
    <a href="https://github.com/hmkx/HiNeRV" target="_blank" style="font-style:normal;">[code]</a>   
    </td>
    </tr>
    </tbody></table>
    <!-- <a href="https://github.com/crispianm/ST-MFNet-Mini" target="_blank"><p class="lab la-github"></p>&#32;</a>
    <a href="https://github.com/crispianm/ST-MFNet-Mini" target="_blank" style="font-style:normal;">github</a>&#8201;&#8201;&#8201; -->
<!-- </div> -->
</div>
<br>



<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td class="thumbs"><p>
        </p><div class="col-sm-3 abbr"><abbr class="badge">TIP 2023</abbr></div>
        <img src="https://danier97.github.io/thumbnails/bvivfip2.PNG" width="100%">
    <p></p></td>
    <td class="detail">   
    <b id="papertitle"> BVI-VFI: A Video Quality Database for Video Frame Interpolation </b>
    <br>
    Duolikun Danier, Fan Zhang, David Bull
    <br>
    <em>IEEE Transactions on Image Processing</em> (<b>TIP</b>), 2023
    <br>
    <a href="https://doi.org/10.1109/TIP.2023.3327912" target="_blank" style="font-style:normal;">[paper]</a>   

    <a href="https://arxiv.org/abs/2210.00823v3" target="_blank" style="font-style:normal;">[arXiv]</a>   

    <a href="https://danier97.github.io/BVI-VFI-database/" target="_blank" style="font-style:normal;">[project]</a>   

    <a href="https://forms.office.com/Pages/ResponsePage.aspx?id=MH_ksn3NTkql2rGM8aQVG1fDz7azbERMp_0LZtGJZ19UQlFMREhWU0E3QzRVMkYyT0VFTUg3T041Qy4u" target="_blank" style="font-style:normal;">[database]</a>   

    <a href="https://github.com/danier97/BVI-VFI-database" target="_blank" style="font-style:normal;">[github]</a>   

    </td>
    </tr>
    </tbody></table>
<!-- </div> -->
</div>
<br>

<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td class="thumbs"><p>
        </p><div class="col-sm-3 abbr"><abbr class="badge">CVPR 2022</abbr></div>
        <img src="https://danier97.github.io/ST-MFNet/overall.svg" width="100%">
    <p></p></td>
    <td class="detail">
    <b id="papertitle"> ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation </b>
    <br>
    Duolikun Danier, Fan Zhang, David Bull
    <br>
    <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022
    <br>
    <a href="https://arxiv.org/abs/2111.15483" target="_blank" style="font-style:normal;">[arXiv]</a>   

    <a href="https://danier97.github.io/ST-MFNet/" target="_blank" style="font-style:normal;">[project]</a>   


    <a href="https://github.com/danier97/ST-MFNet" target="_blank" style="font-style:normal;">[code]</a>   
    </td>
    </tr>
    </tbody></table>
<!-- </div> -->
</div>
<br>

<div class="container-md">
    <table class="papers" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td class="thumbs"><p>
        </p><div class="col-sm-3 abbr"><abbr class="badge">TMM 2021</abbr></div>
        <img src="./BVI-DVC/BVI-DVC.jpg" width="100%">
    <p></p></td>
    <td class="detail">
    <b id="papertitle"> BVI-DVC: A Training Database for Deep Video Compression </b>
    <br>
    Di Ma, Fan Zhang, David Bull
    <br>
    <em>IEEE Transactions on Multimedia</em> (<b>TMM</b>), 2021
    <br>
	    <a href="https://doi.org/10.1109/TMM.2021.3108943" target="_blank" style="font-style:normal;">[paper]</a>   
    <a href="https://arxiv.org/abs/2003.13552" target="_blank" style="font-style:normal;">[arXiv]</a>   

    <a href="https://fan-aaron-zhang.github.io/BVI-DVC/" target="_blank" style="font-style:normal;">[project]</a>   


    <a href="https://forms.office.com/r/d1VNeeBxrj" target="_blank" style="font-style:normal;">[database]</a>   
    </td>
    </tr>
    </tbody></table>
<!-- </div> -->
</div>
<br>




 </div>

            <hr />
			
			
            <div class="container-md">
                <h2 id="projects">Full Publication List</h2>


<br>
<b>Book and Book Chapters</b>


<ol start="1">
<li>Intelligent Image and Video Compression: Communicating Pictures. <a href='https://www.amazon.co.uk/Image-Video-Compression-Communicating-Pictures/dp/0128203536/'>[book]</a><a href="Intelligent-Image-and-Video-Compression.htm">[resource]</a>
<br>
D. Bull and F. Zhang, <em>2nd Edition</em>, Oxford: Academic Press, 2021.
<br>
<br>
<li>Measuring video quality. <A HREF="http://www.sciencedirect.com/science/article/pii/B9780124201491000077">[book]</A>
<br>
F. Zhang and D. Bull, <em>In: Sergios Theodoridis and Rama Chellappa, editors, Academic Press Library in Signal Processing. Vol 5. </em>, Oxford: Academic Press, 2014, pp 227-249. ISBN: 978-0-12-420149-1.
<br>

</ol>






<b>MPEG Standard Contributions</b>



<ol start="1">
<li>Description of SDR video coding technology proposal by University of Bristol (JVET-J0031) <A HREF="http://phenix.it-sudparis.eu/jvet/doc_end_user/current_document.php?id=3432">[document]</A>
<br>
D. Bull, F. Zhang and M. Afonso, <em>A submission to the Joint Call for Proposals on Video Compression with Capability beyond HEVC,</em> April 2018 in San Diego.
<br>
<p>
<li>BVI_Texture UHD 120fps test sequences for HEVC and beyond (JCTVC-V0099) <A HREF="http://phenix.int-evry.fr/jct/doc_end_user/current_document.php?id=10306">[document]</A>
<br>
M. Papadopoulos, F. Zhang, D. Agrafiotis, D. Bull and J.-R. Ohm,</em> October 2015 in Geneva.
<br>
<p>

</ol>





<b>arXiv Papers</b>


<ol start="1">
<li> MTKD: Multi-Teacher Knowledge Distillation for Image Super-Resolution. <A HREF="https://arxiv.org/abs/2404.09571">[paper]</A>
<br>
Y. Jiang, C. Feng, F. Zhang, D. Bull, arXiv:2404.09571, 2024.
<br>
<p>
<li> Enhancing HDR Video Compression through CNN-based Effective Bit Depth Adaptation. <A HREF="https://arxiv.org/abs/2207.08634">[paper]</A>
<br>
C. Feng, Z. Qi, D. Danier, F. Zhang, X. Xu, S. Liu, D. Bull, arXiv:2207.08634, 2022.
<br>
<p>



</ol>



<b>Journal Papers</b>

<ol start="1">
<li> CVEGAN: a perceptually-inspired GAN for compressed video enhancement. <A HREF="https://arxiv.org/abs/2011.09190">[paper]</A><A HREF="CVE-GAN/index.htm">[project & code]</A>
<br>
D. Ma, F. Zhang, and D. R. Bull, accepted by <em>Signal Processing: Image Communication</em>, 2024.
<br>
<p>
<li> BVI-VFI: A Video Quality Database for Video Frame Interpolation. <A HREF="https://arxiv.org/abs/2210.00823">[paper]</A><A HREF="https://danielism97.github.io/BVI-VFI-database/">[project & database]</A>
<br>
D. Danier, F. Zhang and D. Bull, <em>IEEE Trans. on Image Processing</em>, 2024.
<br>
<p>
<li> A multiple-UAV architecture for autonomous media production. <A HREF="https://link.springer.com/article/10.1007/s11042-022-13319-8">[paper]</A>
<br>
I. Mademlis, A. Torres-Gonzalez, J. Capitan, M. Montagnuolo, A. Messina, F. Negro, C. Le Barz, T. Goncalves, R. Cunha, B. Guerreiro, F. Zhang, S. Boyle, G. Guerout, A. Tefas, N. Nikolaidis, D. Bull and I. Pitas, <em>Multimedia Tools and Applications</em>, 2023.
<br>
<p>
<li> BVI-CC: A Dataset for Research on Video Compression and Quality Assessment. <A HREF="https://www.frontiersin.org/articles/10.3389/frsip.2022.874200/full">[paper]</A><a href="https://vilab.blogs.ilrt.org/?p=2295">[dataset]</a>
<br>
A. V. Katsenou, F. Zhang, M. Afonso, G. Dimitrov and D. R. Bull, <em>Frontiers in Signal Processing</em>, 2022.
<br>
<p>
<li> Optimising VVC Encoding Using Key Frame Selection. <A HREF="https://www.iieej.org/journal/trans-on-ievc-vol-9-no-2/">[paper]</A>
<br>
S. Nagaraju, F. Zhang, S. Takamura, D. R. Bull, <em>IIEEJ Transactions On Image Electronics</em>, 2021.
<br>
<p>
<li> BVI-DVC: A Training Database for Deep Video Compression. <A HREF="https://arxiv.org/abs/2003.13552">[paper]</A><a href="BVI-DVC/index.htm">[dataset]</a>
<br>
D. Ma, F. Zhang, and D. R. Bull, <em>IEEE Trans. on Multimedia</em>, 2021.
<br>
<p>
<li>ViSTRA2: Video Coding using Spatial Resolution and Effective Bit Depth Adaptation. <A HREF="https://arxiv.org/abs/1911.02833">[paper]</A><a href="https://vilab.blogs.bristol.ac.uk/?p=2278">[project]</a>
<br>
F. Zhang, M. Afonso and D. R. Bull, <em>Elsevier Signal Processing Image Communication</em>, 2021.
<p>
<li> Video Compression with CNN-based Post Processing. <A HREF="https://arxiv.org/abs/2009.07583">[paper]</A><a href="CNN-PP/index.htm">[project]</a>
<br>
F. Zhang, D. Ma, C. Feng and D. R. Bull, <em>IEEE MultiMedia Magazine</em>, 2020.
<br>
<p>
<li> MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering. <A HREF="https://arxiv.org/abs/2007.07099">[paper]</A>
<br>
D. Ma, F. Zhang, and D. R. Bull, <em>IEEE Journal of Selected Topics in Singal Processing</em>, 2020.
<br>
<p>
<li>A Study of High Frame Rate Video Formats. <A HREF="https://ieeexplore.ieee.org/document/8531714">[paper]</A><a href="BVI-HFR/">[project]</a><a href="BVI-HFR/">[dataset]</a>
<br>
A. Mackin, F. Zhang, and D. R. Bull, <em>IEEE T-MM,</em> 2019.
<br>
<p>
<li>Video Compression based on Spatio-Temporal Resolution Adaptation. <A HREF="https://ieeexplore.ieee.org/document/8517114">[paper]</A><a href="ViSTRA/">[project]</a>
<br>
M. Afonso, F. Zhang and D. R. Bull, <em>IEEE T-CSVT (Letter),</em> 2019.
<br>
<p>
<li>Rate-distortion Optimization Using Adaptive Lagrange Multipliers.  <A HREF="https://ieeexplore.ieee.org/document/8482327">[paper]</A><a href="RDO/">[project]</a>
<br>
F. Zhang and D. R. Bull, <em>IEEE T-CSVT,</em> 2019.
<br>
<p>
<li>BVI-HD: A Video Quality Database for HEVC Compressed and Texture Synthesised Content. <A HREF="https://ieeexplore.ieee.org/document/8322297">[paper]</A><a href="BVI-HD/">[dataset]</a>
<br>
F. Zhang, F. Mercer Moss, R. Baddeley and D. R. Bull, <em>IEEE T-MM,</em> 2018.
<br>
<p>
<li>Reduced-Reference Video Quality Metric Using Spatial Information in Salient Regions.  <A HREF="http://journal.uad.ac.id/index.php/TELKOMNIKA/article/view/9036/pdf_679">[paper]</A>
<br>
F. D. A. Rahman, D. Agrafiotis, O. O. Khalifa and F. Zhang, <em>TELKOMNIKA (Telecommunication Computing Electronics and Control),</em> 2018.
<br>
<p>
<li>On the Optimal Presentation Duration for Subjective Video Quality Assessment.  <A HREF="https://ieeexplore.ieee.org/document/7172512">[dataset]</A><a href="Duration/index.htm">[project]</a>
<br>
F. Mercer Moss, K. Wang, F. Zhang, R. Baddeley and D. Bull, <em>IEEE T-CSVT,</em> November 2016.
<br>
<p>
<li>Support for Reduced Presentation Durations in Subjective Video Quality Assessment. <A HREF="http://www.sciencedirect.com/science/article/pii/S0923596516301126">[paper]</A><a href="Duration/index.htm">[project]</a>
<br>
F. Mercer Moss, C.-T. Yeh, F. Zhang, R. Baddeley, D. R. Bull, <em>Elsevier Signal Processing: Image Communication,</em> October 2016.
<br>
<p>
<li>A Perception-based Hybrid Model for Video Quality Assessment <A HREF="https://ieeexplore.ieee.org/document/7100892">[paper]</A><a href="VQA/PVM_code.zip">[code]</a><a href="VQA/index.htm">[project]</a>
<br>
F. Zhang and D. Bull, <em>IEEE T-CSVT,</em> June 2016.
<br>
<p>
<li>Perception-oriented Video Coding based on Image Analysis and Completion: a Review. <A HREF="http://www.sciencedirect.com/science/article/pii/S0923596512000100">[paper]</A>
<br>
P. Ndjiki-Nya, D. Doshkov, H. Kaprykowsky, F. Zhang, D. Bull, T. Wiegand, <em>Signal Processing: Image Communication</em>, July 2012.
<br>
<p>
<li>A Parametric Framework For Video Compression Using Region-based Texture Models. <A HREF="https://ieeexplore.ieee.org/document/5986673">[paper]</A><a href="PVC/">[project]</a>
<br>
F. Zhang and D. Bull, <em>IEEE J-STSP</em>, November 2011.
<br>

</ol>



<b>Conference Contributions</b>

<ol start="1">
<li> LDMVFI: Video Frame Interpolation with Latent Diffusion Models. <A HREF="https://arxiv.org/abs/2303.09508">[paper]</A><A HREF="https://github.com/danielism97/ldmvfi">[source code]</A>
<br>
D. Danier, F. Zhang, D. Bull, accepted by AAAI, 2024.
<br>
<p>
<li> RankDVQA: Deep VQA based on Ranking-inspired Hybrid Training. <A HREF="https://arxiv.org/abs/2202.08595">[paper]</A><A HREF="https://chenfeng-bristol.github.io/RankDVQA/">[source code]</A>
<br>
C. Feng, D. Danier, F. Zhang, and D. R. Bull, IEEE/CVF WACV 2024.
<br>
<p>
<li> Immersive Video Compression using Implicit Neural Representations. <A HREF="https://arxiv.org/abs/2402.01596">[paper]</A>
<br>
H M Kwan, F Zhang, A Gower, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> Compressing Deep Image Super-resolution Models. <A HREF="https://arxiv.org/abs/2401.00523">[paper]</A><A HREF="https://pikapi22.github.io/CDISM/">[source code]</A>
<br>
Y Jiang, J Nawala, F Zhang, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> Full-reference Video Quality Assessment for User Generated Content Transcoding. <A HREF="https://arxiv.org/abs/2312.12317">[paper]</A>
<br>
Z Qi, C Feng, D Danier, F Zhang, X Xu, S Liu, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> RankDVQA-mini: Knowledge Distillation-Driven Deep Video Quality Assessment. <A HREF="https://arxiv.org/abs/2312.08864">[paper]</A>
<br>
C Feng, D Danier, H Wang, F Zhang, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> BVI-Artefact: An Artefact Detection Benchmark Dataset for Streamed Videos. <A HREF="https://arxiv.org/abs/2312.08859">[paper]</A>
<br>
C Feng, D Danier, F Zhang, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> Accelerating Learnt Video Codecs with Gradient Decay and Layer-wise Distillation. <A HREF="https://arxiv.org/abs/2312.02605">[paper]</A>
<br>
T Peng, G Gao, H Sun, F Zhang, D Bull, accepted by PCS, 2024.
<br>
<p>
<li> HiNeRV: Video Compression with Hierarchical Encoding based Neural Representation. <A HREF="https://arxiv.org/abs/2306.09818">[paper]</A><A HREF="https://github.com/hmkx/HiNeRV">[source code]</A>
<br>
Ho Man Kwan, Ge Gao, Fan Zhang, Andrew Gower, David Bull, NeurIPS 2023.
<br>
<p>
<li> ST-MFNet Mini: Knowledge Distillation-Driven Frame Interpolation. <A HREF="https://arxiv.org/abs/2302.08455">[paper]</A><A HREF="https://github.com/crispianm/ST-MFNet-Mini">[source code]</A>
<br>
C. Morris, D. Danier, F. Zhang, N. Anantrasirichai and D. Bull, ICIP, 2023.
<br>
<p>
<li> ST-MFNet: Spatio-Temporal Multi-Flow Network for Video Frame Interpolation. <A HREF="https://arxiv.org/abs/2111.15483">[paper]</A><A HREF="https://danielism97.github.io/ST-MFNet/">[project & Code]</A>
<br>
D. Danier, F. Zhang, and D. R. Bull, IEEE/CVF CVPR, 2022
<br>
<p>
<li> Analysis of video quality induced spatio-temporal saliency shifts. <A HREF="https://ieeexplore.ieee.org/iel7/9897158/9897159/09897995.pdf">[paper]</A>
<br>
X. Wu, Z. Dong, F. Zhang, P. L. Rosin and H. Liu, IEEE ICIP, 2022
<br>
<p>
<li> Identifying pitfalls in the evaluation of saliency models for videos. <A HREF="https://orca.cardiff.ac.uk/id/eprint/151812/1/IVMSP_2022.pdf">[paper]</A>
<br>
Z. Dong, X. Wu, X. Zhao, F. Zhang, and H. Liu, IEEE IVMSP Workshops, 2022
<br>
<p>
<li> FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation. <A HREF="https://arxiv.org/abs/2207.08119">[paper]</A><A HREF="https://danielism97.github.io/FloLPIPS/">[project & Code]</A>
<br>
D. Danier, F. Zhang, and D. Bull, PCS, 2022.
<br>
<p>
<li> Enhancing VVC with Deep Learning based Multi-Frame Post-Processing. <A HREF="https://arxiv.org/abs/2205.09458">[paper]</A>
<br>
D. Danier, C. Feng, F. Zhang, and D. R. Bull, 5th Challenge on Learned Image Compression (in IEEE/CVF CVPR), 2022
<br>
<p>
<li> Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN. <A HREF="https://arxiv.org/abs/2202.07731">[paper]</A><A HREF="https://danielism97.github.io/EDC/">[project & code]</A>
<br>
D. Danier, F. Zhang, and D. R. Bull, accepted by ICIP 2022.
<br>
<p>
<li> A CNN-based Post-Processor for Perceptually-Optimized Immersive Media Compression. <A HREF="https://arxiv.org/abs/2202.12852">[paper]</A>
<br>
A. Katsenou, F. Zhang, and D. R. Bull, accetpted by ICIP 2022.
<br>
<p>
<li> A Subjective Quality Study for Video Frame Interpolation. <A HREF="https://arxiv.org/abs/2202.07727">[paper]</A><A HREF="https://danielism97.github.io/BVI-VFI/">[project]</A>
<br>
D. Danier, F. Zhang, and D. R. Bull, accetpted by ICIP 2022.
<br>
<p>
<li>ViSTRA3: Video Coding with Deep Parameter Adaptation and Post Processing. <A HREF="https://arxiv.org/abs/2111.15536">[paper]</A>
<br>
C. Feng, D. Danier, C. Tan, F. Zhang, D. Bull, Grand Challenge on Neural Network-based Video Coding in IEEE ISCAS, 2022
<br>
<p>
<li>Enhancing VMAF through New Feature Integration and Model Combination. <A HREF="https://arxiv.org/abs/2103.06338">[paper]</A>
<br>
Fan Zhang, Angeliki Katsenou, Christos Bampis, Lukas Krasula, Zhi Li and David Bull, <em>PCS</em>, 2021.
<br>
<p>
<li>A Subjective Study on Videos at Various Bit Depths. <A HREF="https://arxiv.org/abs/2103.10363">[paper]</A>
<br>
Alex Mackin, Di Ma, Fan Zhang and David Bull, <em>PCS</em>, 2021.
<br>
<p>
<li>VMAF-based Bitrate Ladder Estimation for Adaptive Streaming. <A HREF="https://arxiv.org/abs/2103.07564">[paper]</A>
<br>
Angeliki V. Katsenou, Fan Zhang, Kyle Swanson, Mariana Afonso, Joel Sole and David R. Bull, <em>PCS</em>, 2021.
<br>
<p>
<li>Key Reference Frame Selection for VVC Encoding. <A HREF="https://www.jstage.jst.go.jp/article/aiieej/49/0/49_12/_article/-char/ja/">[paper]</A>
<br>
S. Nagaraju, F. Zhang, S. Takamura, D. R. Bull, <em>Proceedings of the 49th Annual Conference of the Institute of Image Electronics Engineers of Japan</em>, 2021.
<br>
<p>
<li>Enhancing VVC through CNN-based Post-Processing. <A HREF="https://ieeexplore.ieee.org/document/9102912">[paper]</A><a href="CNN-PP/index.htm">[project]</a>
<br>
F. Zhang, C. Feng and D. Bull, <em>ICME,</em> 2020.
<br>
<p>
<li>A Simulation Environment for Drone Cinematography. <A HREF="https://www.ibc.org/technical-papers/a-simulation-environment-for-drone-cinematography/6747.article">[paper]</A>
<br>
F. Zhang, D. Hall, T. Xu, S. Boyle and D. Bull, <em>IBC,</em> 2020.
<br>
<p>
<li>Video compression with low complexity CNN-based spatial resolution adaptation. <A HREF="https://arxiv.org/abs/2007.14726">[paper]</A>
<br>
D. Ma, F. Zhang, and D. Bull, <em>SPIE,</em> 2020.
<br>
<p>
<li>GAN-based Effective Bit Depth Adaptation for Perceptual Video Compression. <A HREF="https://ieeexplore.ieee.org/document/9102865">[paper]</A>
<br>
D. Ma, F. Zhang and D. Bull, <em>ICME,</em> 2020.
<br>
<p>
<li>Encoding in the Dark Grand Challenge: An Overview. <A HREF="https://ieeexplore.ieee.org/document/9106011">[paper]</A>
<br>
N. Anantrasirichai, F. Zhang, A. Malyugina, P. Hill, A. Katsenou, <em>ICME Workshops,</em> 2020.
<br>
<p>
<li>Enhanced Video Compression based on Effective Bit Depth Adaptation. <A HREF="https://ieeexplore.ieee.org/document/8803185">[paper]</A>
<br>
F. Zhang, M. Afonso and D. Bull, <em>ICIP,</em> 2019.
<br>
<p>
<li>A Subjective Study of Viewing Experience for Drone VIdeos Using Simulated Content. <A HREF="https://ieeexplore.ieee.org/document/8803747">[paper]</A>
<br>
S. Boyle, F. Zhang and D. Bull, <em>ICIP,</em> 2019.
<br>
<p>
<li>A Subjective Comparison of AV1 and HEVC for Adaptive Video Streaming. <A HREF="https://ieeexplore.ieee.org/document/8803523">[paper]</A><a href="https://vilab.blogs.ilrt.org/?p=2295">[dataset]</font></a>
<br>
A. Katsenou, F. Zhang, M. Afonso and D. Bull, <em>ICIP,</em> 2019.
<br>
<p>
<li>Frame Rate Conversion Method based on a Virtual Shutter Angle. <A HREF="https://ieeexplore.ieee.org/document/8803489">[paper]</A>
<br>
A. Mackin, F. Zhang and D. Bull, <em>ICIP,</em> 2019.
<br>
<p>
<li>Environment Capture and Simulation for UAV Cinematography Planning and Training. <A HREF="http://eusipco2019.org/wp-content/uploads/2019/08/Environment_Capture_and_Simulation_for_UAV_Cinematography_Planning_and_Training.pdf">[paper]</A>
<br>
S. Boyle, M. Newton, F. Zhang and D. Bull, <em>EUSIPCO,</em> 2019.
<br>
<p>
<li>Perceptually-inspired Super-resolution of Compressed Videos. <A HREF="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11137/1113717/Perceptually-inspired-super-resolution-of-compressed-videos/10.1117/12.2530688.short">[paper]</A>
<br>
D. Ma, M. Afonso, F. Zhang and D. Bull, <em>SPIE,</em> 2019.
<br>
<p>
<li>The Future of Media Production Through Multi-drones' Eyes. <A HREF="https://personal.us.es/jcapitan/preprint/messina_ibc18_web.pdf">[paper]</A>
<br>
A. Messina, S. Metta, M. Montagnuolo, F. Negro, V. Mygdalis, I. Pitas, J. Capitan, A. Torres, S. Boyle, D. Bull and F. Zhang, <em>IBC,</em> 2018.
<br>
<p>
<li>A study of subjective video quality at various spatial resolutions. <A HREF="https://ieeexplore.ieee.org/document/8451225">[paper]</A><a href="BVI-SR/">[dataset]</a>
<br>
A. Mackin, M. Afonso, F. Zhang and D. Bull, <em>ICIP,</em> 2018.
<br>
<p>
<li>Spatial resolution adaptation framework for video compression. <A HREF="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10752/107520L/Spatial-resolution-adaptation-framework-for-video-compression/10.1117/12.2320520.short?SSO=1">[paper]</A>
<br>
M. Afonso, F. Zhang and D. Bull, <em>SPIE,</em> 2018.
<br>
<p>
<li>SRQM: A Video Quality Metric for Spatial Resolution Adaptation. <A HREF="https://ieeexplore.ieee.org/document/8456246">[paper]</A><a href="https://vilab.blogs.bristol.ac.uk/?p=2180">[code]</a>
<br>
A. Mackin, M. Afonso, F. Zhang and D. Bull, <em>PCS,</em> 2018.
<br>
<p>
<li>A Frame Rate Dependent Video Quality Metric based on Temporal Wavelet Decomposition and Spatiotemporal Pooling. <A HREF="http://ieeexplore.ieee.org/document/8296291">[paper]</A><a href=https://vilab.blogs.bristol.ac.uk/?p=2265">[code]</a>
<br>
F Zhang, A Mackin and D. R. Bull, <em>ICIP,</em> 2017.
<br>
<p>
<li>Low Complexity Video Coding Based on Spatial Resolution Adaptation. <A HREF="http://ieeexplore.ieee.org/document/8296835">[paper]</A>
<br>
M. Afonso, F. Zhang, A. Katsenou, D. Agrafiotis, D. Bull, <em>ICIP,</em> 2017.
<br>
<p>
<li>Investigating the Impact of High Frame Rates on Video Compression. <A HREF="https://ieeexplore.ieee.org/document/8296290">[paper]</A><a href="https://data.bris.ac.uk/data/dataset/k8bfn0qsj9fs1rwnc2x75z6t7">[dataset]</a>
<br>
A. Mackin, F. Zhang, M. A. Papadopoulos, D. Bull, <em>ICIP,</em> 2017.
<br>
<p>
<li>Video Texture Analysis based on HEVC Encoding
Statistics. <A HREF="https://ieeexplore.ieee.org/document/7906312">[paper]</A><a href="https://data.bris.ac.uk/data/dataset/1h2kpxmxdhccf1gbi2pmvga6qp">[dataset]</a>
<br>
M. Afonso, A. Katsenou, F. Zhang, D. Agrafiotis, D. Bull, <em>PCS,</em> 2016.
<br>
<p>
<li>HEVC Enhancement using Content-based Local QP Selection. <A HREF="https://ieeexplore.ieee.org/document/7533154">[paper]</A>
<br>
F. Zhang and D. Bull, <em>ICIP,</em> 2016.
<br>
<p>
<li>An Adaptive QP Offset Determination Method for HEVC. <A HREF="https://ieeexplore.ieee.org/document/7533155">[paper]</A>
<br>
 M. A. Papadopoulos, F. Zhang, D. Agrafiotis, D. R. Bull, <em>ICIP,</em> 2016.
<br>
<p>
<li>What's on TV: A Large Scale Quantitative Characterisation of Modern Broadcast Video Content. <A HREF="https://ieeexplore.ieee.org/document/7532794">[paper]</A><a href="https://vilab.blogs.ilrt.org/?p=1554">[project]</a>
<br>
F. Mercer Moss, F. Zhang, R. Baddeley, D. R. Bull, <em>ICIP,</em> 2016.
<br>
<p>
<li> An Adaptive Lagrange Multiplier Determination Method for Rate-distortion Optimisation in Hybrid Video Codecs. <A HREF="https://ieeexplore.ieee.org/document/7350883">[paper]</A><a href="https://vilab.blogs.ilrt.org/?p=2268">[project]</a>
<br>
F. Zhang and D. Bull, <em>ICIP,</em> 2015.
<br>
<p>
<li>A Study of Subjective Video Quality at Various Frame Rates.  <A HREF="https://ieeexplore.ieee.org/document/7351436">[paper]</A><a href="BVI-HFR/index.htm">[dataset]</a>
<br>
A. Mackin, F. Zhang and D. Bull, <em>ICIP,</em> 2015.
<br>
<p>
<li>A Very Low Complextiy Reduced Reference Video Quality Metric based on Spatio-temporal Information Selection. <A HREF="https://ieeexplore.ieee.org/document/7350863">[paper]</A>
<br>
M. Wang, F. Zhang and D. Agrafiotis, <em>ICIP,</em> 2015.
<br>
<p>
<li>A Video Texture Database for Perceptual Compression and Quality Assessment. <A HREF="https://ieeexplore.ieee.org/document/7351309">[paper]</A><a href="https://data.bris.ac.uk/datasets/1if54ya4xpph81fbo1gkpk5kk4/">[dataset]</a>
<br>
M. A. Papadopoulos, F. Zhang, D.Agrafiotis and D. Bull, <em>ICIP,</em> 2015.
<br>
<p>
<li>Optimal sequence duration for subjective video quality assessment. <A HREF="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=2444238">[paper]</A><a href="Duration/index.htm">[project]</a>
<br>
F. J. Mercer Moss, K. Wang, F. Zhang, R. Baddeley and D. Bull, <em>SPIE Optical Engineering+ Applications,</em> 2015.
<br>
<p>
<li>Quality Assessment Methods for Perceptual Video Compression. <A HREF="https://ieeexplore.ieee.org/document/6738009">[paper]</A><a href="http://vilab.blogs.ilrt.org/files/2016/06/PVM_code.zip">[code]</a><a href="https://vilab.blogs.ilrt.org/?p=787">[project]</a>
<br>
F. Zhang and D. Bull, <em>ICIP,</em> Melbourne, Australia, September 2013.
<br>
<p>
<li>Production of high dynamic range video. <A HREF="http://www.bbc.co.uk/rd/publications/whitepaper269">[paper]</A>
<br>
M. Price, D. Bull, T. Flaxton, S. Hinde, R. Salmon, A. Sheikh, G. Thomas, and F. Zhang, <em>IBC</em>, Amsterdam, September, 2013.
<br>
<p>
<li>Advances in Region-based Texture Modeling for Video Compression. <A HREF="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1267237">[paper]</A><a href="https://vilab.blogs.ilrt.org/?page_id=553">[project]</a>
<br>
F. Zhang and D. Bull, <em>Proc. SPIE 8135</em>, San Diego, USA, August, 2011.
<br>
<p>
<li> Enhanced Video Compression With Region-Based Texture Models. <A HREF="https://ieeexplore.ieee.org/document/5702560">[paper]</A><a href="https://vilab.blogs.ilrt.org/?page_id=553">[project]</a>
<br>
F. Zhang and D. Bull, <em>PCS</em>, Nagoya, Japan, December, 2010.
<br>
<p>
<li> Region-Based Texture Modelling For Next Generation Video Codecs <A HREF="https://ieeexplore.ieee.org/document/5651626">[paper]</A><a href="https://vilab.blogs.ilrt.org/?page_id=553" >[project]</a>
<br>
F. Zhang, D. Bull, and N. Canagarajah, <em>ICIP</em>, Hong Kong, China, September, 2010.
<br>

</ol>


<b>Other Publications</b>

<ol start="1">
<li> Exploring the Challenges of Higher Frame Rates:
from Quality Assessment to Frame Rate Selection. <A HREF="http://mmc.committees.comsoc.org/files/2018/07/01-MMTC_Communication_Frontier_May_2018-Final-Revised.pdf">[paper]</A><a href="https://vilab.blogs.ilrt.org/?p=1563">[project]</a>
<br>
A. V. Katsenou, A. Mackin, D. Ma, F. Zhang and D. R. Bull, <em>IEEE COMSOC MMTC Communications - Frontiers (E-Letter),</em> May 2018 (invited).
<br>
<p>
</ol>



<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11440198;
var sc_invisible=0;
var sc_security="e7e7610e";
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11440198/0/e7e7610e/0/" alt="web
analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->

            </div>
            <hr />
        </div>
    </div>
	<script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
<script>
      $(function() {
	  var olderNews = $("#olderNews");
	  olderNews.hide();
	  $("#showOlderNews").click(function() {
	      olderNews.show(1000);
	  });
      });
</script>

<script>
      $(function() {
	  var olderNews = $("#olderProjects");
	  olderNews.hide();
	  $("#showOlderProjects").click(function() {
	      olderNews.show(1000);
	  });
      });
</script>

</body>

</html>
