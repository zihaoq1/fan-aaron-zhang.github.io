<HTML>

<HEAD>
   <TITLE>
      Intelligent Image and Video Compression: Communicating Pictures, 2nd Edition
   </TITLE>
   <META name="keywords" content="Intelligent Image and Video Compression, Communicating Pictures, David Bull, Fan Zhang">
   <STYLE>
   <!--
	  a
		{
		text-decoration:none;
		}
		a:hover
		{
  	color: white;
  	background-color: #CC0066;
		}
		td
		{
		width: 900;
		}
		//-->
	</STYLE>
</HEAD>

<BODY  BGCOLOR="#FFFFFF" text="#000000" link="#8B008B" vlink="#008B8B" alink="#4B0082">

<!--
<center>
<H2> <font face="papyrus" color="#FF6666" SIZE="20">&nbsp;Fan (Aaron) ZHANG's Home Page&nbsp;</font> </H2>
</center>
-->
<font face="Times New Roman" size=3>
<p>
<p>
<p>


<table cellspacing=40 cellpadding=5>
<tr>
<p>
<td>
<b><font face="cursive" color="#000000" SIZE="6"><A HREF="https://www.elsevier.com/books/communicating-pictures/bull/978-0-12-405906-1"> Intelligent Image and Video Compression: Communicating Pictures, 2nd Edition </A></font>
<p>
<b><font face="Times New Roman" color="#000000" SIZE="4"> By </font><font face="papyrus" color="#000000" SIZE="4">David Bull and Fan Zhang</font></b>
</b>
</td>
</tr>

<tr>
<p>
<td valign=top>
<img src="book.jpg" align=center border=0>
</td>
</tr>


<tr>
<p>
<td valign=top>
<b><font face="papyrus" color="#FF6666" SIZE="5">Introduction</font></b>
<p>
<font size=+1>
This book explains the requirements, analysis, design and application of a modern video coding system. It draws on the authors' extensive academic and professional experience in this field to deliver a text that is algorithmically rigorous yet accessible, relevant to modern standards and practical. It builds on a thorough grounding in mathematical foundations and visual perception to demonstrate how modern image and video compression methods can be designed to meet the rate-quality performance levels demanded by today's applications and users, in the context of prevailing network constraints.
</td>
</tr>

<tr>
<p>
<td valign=top>
<b><font face="papyrus" color="#FF6666" SIZE="5">Demonstration Software</font></b>
<p>
<font size=+1>
VISTRA is a demonstration software which provides an interactive overview of the some of the key principles of image and video compression, including:

<ul>
  <li>Spatial and temporal redundancy</li>
  <li>Colour channel subsampling</li>
  <li>JPEG image compression</li>
  <li>DCT transform coding</li>
  <li>Motion compensated video compression</li>
  <li>Motion estimation block matching</li>
</ul>

The software and user manual can be downloaded from <A HREF="https://github.com/vilabbris/VISTRA">here</A>.
<p>
<p>
<img src="vistra.png" width=800 align=center border=0>

</td>
</tr>

<tr>
<p>
<td valign=top>
<b><font face="papyrus" color="#FF6666" SIZE="5">Key Features</font></b>
<p>
<font size=+1>
<ul>
  <li>An approach that combines algorithmic rigour with practical implementation using numerous worked examples. </li>
  <li>Explains how video compression methods exploit statistical redundancies and knowledge of human perception to improve performance.</li>
  <li>Uses contemporary video coding standards (HEVC and H.264/AVC) as a vehicle for explaining block-based compression. </li>
  <li>Provides broad coverage of important topics such as visual quality assessment and video transmission.</li>
</ul>
</td>
</tr>



<tr>
<p>
<td valign=top>
<b><font face="papyrus" color="#FF6666" SIZE="5">New to this edition</font></b>
<p>
<font size=+1>
<ul>
  <li>Coverage of new more immersive applications: it explains video compression requirements and solutions for HDR and UHDTV, VR, AR and MR. </li>
  <li>Description of new methods capable of measuring viewer engagement and immersion in these applications.</li>
  <li>An introduction to machine learning algorithms and coverage of how these can be used to optimize compression tools, create new coding architectures and enhance quality metric performance. </li>
  <li>Inclusion of the latest advances in perceptual metrics, such as VMAF, and how these can be exploited inside and outside of the coding loop.</li>
  <li>Description of new and extended databases for video quality evaluation and for training machine learning systems; including the use of synthesis and augmentation to enhance coverage.</li>
  <li>Coverage of recent innovations and standards to support adaptive video streaming.</li>
  <li>A more detailed review of the perceptual influences of dynamic range including descriptions of perceptual quantisation, processing and coding  with HLG, PQ, HDR10 and HDR10+.</li>
  <li>A comprehensive update on recent compression standards to include coverage of the key attributes of new and emerging standards such as AV1, VVC and AV2. </li>
  
</ul>
</td>
</tr>




<tr>
<p>
<td valign=top>
<b><font face="papyrus" color="#FF6666" SIZE="5">About the Authors</font></b>
<p>
<font size=+1>

Professor David R. Bull PhD, FIET, FIEEE, CEng obtained his BSc from the University of Exeter, his MSc from the University of Manchester and his PhD from the University of Cardiff. He currently holds the Chair in Signal Processing at the University of Bristol. He is head of the Visual Information Laboratory, Director of Bristol Vision Institute and Director of the UK Government's &#163 46m MyWorld Strength in Places prgramme. David has worked widely across image and video processing focused on streaming, broadcast and wireless applications. He has published over 600 academic papers, various articles and 3 books and has given numerous invited/keynote lectures and tutorials. He has also received numerous awards including the IEE Ambrose Fleming Premium for his work on Primitive Operator Digital Filters a best Paper Award for his work on Link Adaptation for Video Transmission. David's work has been exploited commercially and he has acted as a consultant for companies and governments across the globe.  In 2001, he co-founded ProVision Communication Technologies Ltd., who launched the world's first robust multi-source wireless HD sender for consumer use. His recent award-winning and pioneering work on perceptual video compression using deep learning, has produced world-leading rate-quality performance.
<p>
Dr. Fan (Aaron) Zhang PhD received the B.Sc. (Hons) and M.Sc. degrees from Shanghai Jiao Tong University (2005 and 2008 respectively), and his Ph.D from the University of Bristol (2012). He is currently a Senior Research Associate in the Visual Information Laboratory at the University of Bristol, working on video compression and immersive video processing. His research interests include perceptual video compression, video quality assessment and immersive video formats. Aaron has published over 30 academic papers and has contributed to two books on video compression. His work on super-resolution-based video compression, has contributed to international standardization processes and was a co-winner of the 2017 IEEE Grand Challenge on Video Compression.
</td>
</tr>


</table>
</font>


</BODY>
</HTML>